# -*- coding: utf-8 -*-
"""House Price Prediction

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1nuj3p6LAWU6csjS9frCZhma5sLEudCFZ
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import sklearn
import matplotlib.pyplot as plt
import seaborn as sns

# %matplotlib inline

from sklearn.datasets import fetch_california_housing
california_housing = fetch_california_housing()
california_df = pd.DataFrame(data=california_housing.data, columns=california_housing.feature_names)

print(california_df.keys())

print("MedInc:")
print(california_df.MedInc)

print("HouseAge:")
print(california_df.HouseAge)

print("AveRooms:")
print(california_df.AveRooms)

print("AveBedrms:")
print(california_df.AveBedrms)

print("Population:")
print(california_df.Population)

print("AveOccup:")
print(california_df.AveOccup)

print("Latitude:")
print(california_df.Latitude)

print("Longitude:")
print(california_df.Longitude)

# Display the first five rows
print("First five rows:")
print(california_df.head())

# Display the last five rows
print("\nLast five rows:")
print(california_df.tail())

# Display summary statistics of the DataFrame
print("Summary Statistics:")
print(california_df.describe())

#adding another column to the dataframe then prints
california_df['MEDV'] = california_housing.target
print(california_df.head())

# Check data types of each column in the DataFrame
print("Data Types:")
print(california_df.dtypes)

# Check  summary including data types of each column
print("\nDataFrame Info:")
print(california_df.info())

#check for missing values in each column
print(california_df.isnull().sum())

# Check the column names of the DataFrame
print(california_df.columns)

# Create a box plot using Seaborn
import seaborn as sns
import matplotlib.pyplot as plt

numerical_columns = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude', 'MEDV']

plt.figure(figsize=(20, 8))
sns.boxplot(data=california_df[numerical_columns])
plt.ylim(0, 650)  # Replace with your desired y-axis limits
plt.title("Box Plot of Numerical Features")
plt.show()

# Compute the correlation matrix
correlation_matrix = california_df[numerical_columns].corr()

# Create a heatmap using Seaborn
plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=".2f", linewidths=0.5)
plt.title("Correlation Heatmap")
plt.show()

# Create KDE plots using Seaborn
plt.figure(figsize=(12, 10))

# Loop through numerical columns and create KDE plots
for i, column in enumerate(numerical_columns, 1):
    plt.subplot(3, 3, i)
    sns.kdeplot(california_df[column], fill=True, color='skyblue', alpha=0.5)
    plt.title(f'KDE Plot - {column}')

plt.tight_layout()
plt.show()

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression

# Create feature matrix (X) and target variable (y)
X = california_df[features]
y = california_df[label]

# Split the data into training and testing sets
x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=5)

# Create and train the linear regression model
regressor = LinearRegression()
regressor.fit(x_train, y_train)

# Predict on the test set
y_pred = regressor.predict(x_test)

# Create a DataFrame to compare actual vs predicted values
df = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})
print(df)

from sklearn import metrics

# Calculate evaluation metrics
mae = metrics.mean_absolute_error(y_test, y_pred)
mse = metrics.mean_squared_error(y_test, y_pred)
rmse = metrics.mean_squared_error(y_test, y_pred, squared = False)
r2 = metrics.r2_score(y_test, y_pred)

print(f'Mean Absolute Error (MAE): {mae:.2f}')
print(f'Mean Squared Error (MSE): {mse:.2f}')
print(f'Root Mean Squared Error (RMSE): {rmse:.2f}')
print(f'R2 Score: {r2:.2f}')

#creating an array/target label of any one of the features to return slope and intercept of line
feature = 'AveRooms'
target_label = 'MEDV'

x = np.array(california_df[feature])
y = np.array(california_df[target_label])

# Use polyfit to fit a linear regression line
slope, intercept = np.polyfit(x, y, 1)

# Print the slope and intercept
print(f'Slope: {slope:.4f}')
print(f'Intercept: {intercept:.4f}')

#plotting regression line coressponding ot the feature chose, AveRooms
plt.plot(california_df[feature], slope*california_df[feature] + intercept)
plt.plot(california_df[feature],california_df[target_label],'o')
plt.xlabel("Average Rooms ")
plt.ylabel("Median Value")
plt.ylim(0, 12)

import seaborn as sns
import matplotlib.pyplot as plt

# Create a pairplot using Seaborn
sns.pairplot(california_df, x_vars = ['MedInc', 'HouseAge', 'AveRooms', 'AveBedrms', 'Population', 'AveOccup', 'Latitude', 'Longitude'], y_vars = 'MEDV')
plt.suptitle("Pair Plot of Numerical Features", y=1.02)  # Adjust title position
plt.show()
